---
permalink: /
title: "About Me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
I am currently a **PhD student** at **[Harbin Institute of Technology, Shenzhen](https://www.hitsz.edu.cn)**, engaging in research jointly with **[Peng Cheng Laboratory](https://www.pcl.ac.cn/)**. My PhD work is overseen by **[Prof. Hezhenyu](https://faculty.hitsz.edu.cn/hezhenyu)** from the School of Computer Science at Harbin Institute of Technology, Shenzhen, and **[Prof. Guiweihua](https://pcl.ac.cn/html/918/)** from Peng Cheng Laboratory.

Prior to this, I worked as a **researcher** at **[The Chinese University of Hong Kong, Shenzhen](https://www.cuhk.edu.cn/)**, and the **[Shenzhen Institutes of Artificial Intelligence and Robotics for Society](https://airs.cuhk.edu.cn)**, where I focused on **generative AI** and **extended reality (XR)**. Additionally, I had the honor of being the **inaugural domestic representative** for **WebXR**, organizing efforts that have been highly commended by government bodies and academic scholars.

In addition to my academic and research roles, I act as a **scientific advisor** for multiple artificial intelligence companies, providing expertise in emerging technologies such as the **metaverse**, **3D vision**, **AI avatars**, and **VR/AR/MR**. This position allows me to influence the development of **next-generation AI solutions** across various industries.

I earned my **master's degree** from **Harbin Institute of Technology, Shenzhen**, under the guidance of **Prof. Lijinhui** and **Prof. Hezhenyu**. My research contributions include **more than 10 papers and patents** presented at top international **AI conferences** sponsored by IEEE. I also serve as a **reviewer** for leading conferences such as **NeurIPS, ACM MM, CVPR, ICCV, BMVC, ICML, and ACL**.

Dedicated to advancing **immersive and interactive digital technologies**, I am always open to **academic exchange and collaboration**. I am passionate about leveraging my expertise to foster **innovation** and enhance **user experiences in digital environments**. Please feel free to **contact me** anytime to discuss potential opportunities or ideas in these exciting fields.

Research Interests
======
#Digital Twin‚ÄÉ#Visual SLAM‚ÄÉ#3D Reconstruction‚ÄÉ#XR (AR/VR/MR)‚ÄÉ#LLMs‚ÄÉ#Human-AI Interaction‚ÄÉ#Generative AI‚ÄÉ#Operational Twins‚ÄÉ#Immersive Teleoperation‚ÄÉ#Intelligent Decision Support

News
======
### Academic Services

### üéâ Recent Achievement | ÊúÄÊñ∞ÊàêÊûú

- **2025.7**  
üìÑ **‚ÄúEmpowering Equitable Digital Futures: Integrating Generative AI and 3D/XR Technologies for Culturally Responsive Capacity Building‚Äù**  
‚úÖ Accepted at the **[UNU Macau AI Conference 2025](https://unu.edu/macau/aiconf2025)**, to be held in **Macau SAR, China** on **October 23‚Äì25, 2025**.  
üì∞ This work will appear in the Springer-edited volume _**AI for Humanity: Building an Equitable Digital Future**_, presenting a visionary framework on how **Generative AI and 3D/XR technologies** can drive **culturally responsive digital empowerment**‚Äîreshaping learning, creativity, and life experiences across diverse communities.


- **2025.7** The paper **[MR-MultiTwin: A Mixed Reality Platform for Multi-User Control of Industrial Digital Twins](http://www.ccssta.org.cn/)** presents a platform enabling collaborative multi-user interaction with industrial digital twins through mixed reality. This work has been accepted for the **[2025 IEEE 26th Annual Conference on China Simulation Technology and Application (CCSSTA)](http://www.ccssta.org.cn/)**, to be presented on 2025-07-11 in Shenzhen, China.


- **2025.6** The artwork **_Crypto-Tear: Iris Algorithm_** was selected for **exhibition** at the [**AIART Gallery**](https://aiart-2025.github.io/) of [**IEEE ICME 2025**](https://2025.ieeeicme.org/), held at the **Nantes Congress Centre**, France. As part of the **7th AIART Workshop**, which showcased pioneering efforts in **AI-Generated Content (AIGC)**, the piece delves into the complex interplay between industrialized AI systems and human emotion. It presents a striking visual metaphor that contributes meaningfully to ongoing dialogues surrounding **aesthetics, ethics, and human‚ÄìAI symbiosis**. ü™™ _The work received an official certificate in recognition of its outstanding contribution to the gallery._ View the [artwork here](https://img.fy6b.com/2025/07/10/e79eadfc5e795.jpg) and the [certificate here](https://img.fy6b.com/2025/07/10/f7c707a71e875.png).


### üìù Reviewer Service (2025)

- **2025.6** Invited as **Reviewer** for:  
  - **[NeurIPS 2025 ‚Äì Position Paper Track](https://neurips.cc/)**  
    Officially confirmed as a reviewer. The Position Paper Track emphasizes forward-looking perspectives and foundational insights shaping the future of AI. Further review instructions will be provided by the track chairs.
  - **[1st Workshop on Interactive Human-centric Foundation Models (I-HFM)](https://i-hfm-2025.github.io/I-HFM-2025/)**, in conjunction with [**ICCV 2025**](https://iccv2025.thecvf.com/), Hawaii Convention Center, Honolulu, USA.  
    This workshop focuses on real-time interaction, environmental adaptability, and agent collaboration for AGI-aligned development.  
  - **[3D-VAST: Workshop on 3D Visual Analysis and Scene Understanding Technologies](https://3d-vast.github.io/)**, in conjunction with **ICCV 2025**, Honolulu, Hawaii, USA.  
    The workshop centers on advancements in 3D vision, scene understanding, neural rendering, and multimodal interaction technologies for real-world and industrial applications.


- **2025.6** Invited to serve as a **member of the Editorial Board** for *[Journal of Advances in Engineering Sciences and Technology (JAEST)](https://jaest.cscholar.com/index.php/JAEST/index)*.



- **2025.5** Invited as **Reviewer** for:
  - [**ICML 2025 Workshop on Reliable and Responsible Foundation Models (R2-FM)**](https://r2-fm.github.io/), focusing on trustworthy, ethical, and robust development of foundation models.


- **2025.5** The paper **['PLAT: Predictive LLM-Driven Active Teleoperation with Adaptive Vision and Interaction Optimization'](https://2025.hci.international/)** presents a predictive teleoperation framework leveraging large language models to optimize vision-based control and multimodal human-machine interaction. This work has been accepted for **[HCII 2025](https://2025.hci.international/)**, highlighting novel pathways in enhancing responsiveness and adaptiveness in remote robotic control.

- **2025.5** The paper **['From Digital Twins to Operational Twins: Enhancing Real-Time Human-System Interaction and Adaptive Decision Support with DeepSeek R1'](https://2025.hci.international/)** proposes an advanced ‚ÄúOperational Twins‚Äù framework powered by DeepSeek R1, enabling predictive modeling of operator behavior and real-time AR feedback for intelligent decision support. This paper has been accepted for **[HCII 2025](https://2025.hci.international/)**, contributing to the evolution of digital twin technology in industrial AI.


- **2025.5** Invited as **Reviewer** for:
  - [2nd Workshop on Test-Time Adaptation: Putting Updates to the Test! (PUT)](https://sites.google.com/view/test-time-adaptation/icml-2025-put-workshop), **ICML 2025**, Vancouver, July 18.
  - [SciPy 2025 Proceedings](https://proceedings.scipy.org/articles/proceedings-2024), July 8‚Äì14, Tacoma, WA.
  - [Agents in Interactions, from Humans to Robots Workshop](https://humanrobotinteraction.github.io/aihr-cvpr2025/) (**CVPR 2025**, Nashville, TN).
  - [IEEE ACDSA 2025](https://acidsa.org/) ‚Äî International Conference on Artificial Intelligence, Computer, Data Sciences and Applications.
  - [BMVC 2025](https://bmvc2025.org) ‚Äî accepted the invitation to serve as reviewer for the British Machine Vision Conference 2025.

- **2025.4** Awarded **Outstanding Paper** at the [**3rd Guangdong-Hong Kong-Macao Greater Bay Area Interdisciplinary Doctoral Forum 2025**](https://ias.um.edu.mo/category/%E7%B2%B5%E6%B8%AF%E6%BE%B3%E5%A4%A7%E7%81%A3%E5%8D%80%E8%B7%A8%E5%AD%B8%E7%A7%91%E5%8D%9A%E5%A3%AB%E7%94%9F%E8%AB%96%E5%A3%87/?lang=zh-hant) (Machine Reasoning and Human Reasoning Panel).

- **2025.3** Invited as **Reviewer** for:
  - *Multimodal Foundation Models for Spatial Intelligence* Workshop, [**ACM Multimedia 2025**](https://acmmm2025.org/), Dublin, Oct 27‚Äì28.
  - [**ACL ARR 2025**](https://aclrollingreview.org/) ‚Äì Annual Rolling Review.
  - [**IEEE ICMEIE 2025**](https://www.icmeie.com/) ‚Äì Multimedia Engineering in Industry.

- **2025.2** Invited to be a **member of the Editorial Board** [Journal of Deep Learning and Pattern Recognition](https://img.fy6b.com/2025/02/08/3e5e2a744fb65.png) for **Journal of Deep Learning and Pattern Recognition**.

- **2025.1** Invited to be a **member of the Editorial Board** [Journal of Advances in Engineering and Technology](https://img.fy6b.com/2025/02/08/c4c095d245317.png) for the **Journal of Advances in Engineering and Technology**.

- **2025.1** The paper **['MR-IntelliAssist: A World Cognition Agent for Multimodal Human-AI Collaboration in Smart Manufacturing'](https://arxiv.org/abs/your-paper-link)** introduces a world cognition agent designed to enhance multimodal human-AI collaboration in smart manufacturing. This paper has been accepted for **[HCII 2025](https://2025.hci.international/)**, focusing on advancing smart manufacturing systems through AI-assisted collaboration.

- **2024.12.05** The paper **['DVP-MVS: Synergize Depth-Edge and Visibility Prior for Multi-View Stereo'](https://arxiv.org/abs/2412.11578)** has been **accepted at [AAAI 2025](https://aaai.org/conference/aaai/aaai-25/)**. This work explores the integration of depth-edge and visibility priors to improve multi-view stereo performance, contributing to enhanced 3D reconstruction techniques.

- **2024.12.05** The paper **['MSP-MVS: Multi-Granularity Segmentation Prior Guided Multi-View Stereo'](https://arxiv.org/abs/2407.19323)** has been **accepted at [AAAI 2025](https://aaai.org/conference/aaai/aaai-25/)**. This research introduces a novel approach leveraging multi-granularity segmentation priors to enhance multi-view stereo methods, advancing the field of 3D reconstruction.

- **2024.8.19** The paper **['Visual SLAM with 3D Gaussian Primitives and Depth Priors Enabling Novel View Synthesis'](https://arxiv.org/abs/2408.05635)** has been **accepted for presentation at [CEI 2024](https://2024.ic-cei.org/)**, showcasing advancements in visual SLAM through 3D Gaussian primitives and depth priors for novel view synthesis.

- **2024.6.14** The paper **['Advancements in Translation Accuracy for Stereo Visual-Inertial Initialization'](https://arxiv.org/abs/2405.15082)** details recent advancements in stereo visual-inertial initialization that enhance translation accuracy for XR interaction scenarios. This study has been published in **[IEEE ACIRS 2024](https://ieeexplore.ieee.org/xpl/conhome/10684879/proceeding)** and was selected as an Oral Presentation.

- **2024.3.12** The paper **['BundledSLAM: An Accurate Visual SLAM System Using Multiple Cameras'](https://arxiv.org/abs/2403.19886)** has been accepted for presentation at **[IEEE IAEAC 2024](http://2024.iaeac.org/)**, highlighting significant enhancements in visual SLAM technology.


Honors and Awards
======

-National Scholarship

-National Encouragement Scholarship

-Excellence Award in Zhou Peiyuan Mechanics National Competition

-2nd Prize in International Mathematical Modeling Competition

-1st Prize in National Higher Education Institutions Mathematical Modeling Competition

-First-Class Scholarship(School-level)

-Merit Student(School-level)

-Golden Award in China "Internet +" Innovation and Entrepreneurship Competition(School-Level)

-Personal Honorary Title of "2025 Youth Maker Laboratory" of Harbin Institute of Technology(1/30)


More
======
I am always on the lookout for innovative and technically skilled individuals who share a passion for pushing the boundaries of technology. If you have a keen interest in academia and a spirit of innovation, I would love to explore potential collaborative opportunities. Together, we can drive advancements in our fields and develop solutions that make a significant impact. Whether you are deeply involved in research or are an enthusiast in areas like AI, XR, or any related fields, feel free to reach out to discuss how we might work together to turn visionary ideas into reality.

